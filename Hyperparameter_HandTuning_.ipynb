{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hyperparameter-HandTuning .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o176gKn3yL-O"
      },
      "source": [
        "# P13-1 실습 과제\n",
        "##Mini-batch size & Learning Rate 튜닝"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "achHRPhwHPF3",
        "outputId": "f594b0c8-f60d-433a-9718-0f2131423dda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 682
        }
      },
      "source": [
        "# mlp for the blobs problem with minibatch gradient descent with varied batch size\n",
        "# 아래의 코드에서 다음 두 개의 파라미터를 조합하여 최고의 모델링 성능을 내고 그 결과를 print()로 출력하십시오.\n",
        "# 튜닝할 파라미터 : batch_size & lr (각각 3가지의 옵션이 있으므로 두 파라미터를 조합할 수 있는 경우의 수는 모두 9가지)\n",
        "# 모델의 성능 평가 기준은 다음의 우선순위에 따라 결정하시오. \n",
        "# 1. Validation Loss가 최소, 2. Accuracy는 최고값에 가까울 것\n",
        "# 9번의 실험 후 최적이라고 생각되는 파라미터 값을 코드에 지정하고 셀을 다시 run하여 최종 결과를 출력하시오.\n",
        "%%time\n",
        "from sklearn.datasets import make_blobs\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils import to_categorical\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# prepare train and test dataset\n",
        "def prepare_data():\n",
        "\t# generate 2d classification dataset\n",
        "\tX, y = make_blobs(n_samples=1000, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
        "\t# one hot encode output variable\n",
        "\ty = to_categorical(y)\n",
        "\t# split into train and test\n",
        "\tn_train = 500\n",
        "\ttrainX, testX = X[:n_train, :], X[n_train:, :]\n",
        "\ttrainy, testy = y[:n_train], y[n_train:]\n",
        "\treturn trainX, trainy, testX, testy\n",
        "\n",
        "# fit a model and plot learning curve\n",
        "def fit_model(trainX, trainy, testX, testy, n_batch):\n",
        "\t\n",
        "  # define model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(50, input_dim=2, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dense(3, activation='softmax'))\n",
        "\t\n",
        "  # lr의 값을  0.1, 0.01, 0.001 중에서 선택하여 이곳에 지정\n",
        "\topt = SGD(lr=0.01, momentum=0.9) \n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\t# fit model\n",
        "\thistory = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=150, verbose=2, batch_size=n_batch)\n",
        "\tprint('accuracy = ', format(history.history['accuracy'][149],\".3f\"), ' ', 'validation loss = ', format(history.history['val_loss'][149],\".3f\"))\n",
        "  # plot learning curves\n",
        "\tpyplot.plot(history.history['accuracy'], label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], label='test')\n",
        "\tpyplot.title('batch='+str(n_batch), pad=-40)\n",
        "\n",
        "\n",
        "\n",
        "# prepare dataset\n",
        "trainX, trainy, testX, testy = prepare_data()\n",
        "\n",
        "# batch_size의 값을   16, 32, 64 중에서 선택하여 이곳에 지정\n",
        "batch_size = 64\n",
        "\n",
        "fit_model(trainX, trainy, testX, testy, batch_size)\n",
        "# show learning curves\n",
        "pyplot.show()\n",
        "\n",
        "# 결과를 메모장에 적어놓고 lr과 batch_size를 바꿔가며 최적의 파라미터를 찾아가시오.\n",
        "# 최적의 lr과 batch_size를 선택하여 위의 코드에 적고 Run한 결과룰 출력하여 제출하시오. "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-4068db2ee02a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'from sklearn.datasets import make_blobs\\nfrom keras.layers import Dense\\nfrom keras.models import Sequential\\nfrom keras.optimizers import SGD\\nfrom keras.utils import to_categorical\\nfrom matplotlib import pyplot\\n\\n# prepare train and test dataset\\ndef prepare_data():\\n\\t# generate 2d classification dataset\\n\\tX, y = make_blobs(n_samples=1000, centers=3, n_features=2, cluster_std=2, random_state=2)\\n\\t# one hot encode output variable\\n\\ty = to_categorical(y)\\n\\t# split into train and test\\n\\tn_train = 500\\n\\ttrainX, testX = X[:n_train, :], X[n_train:, :]\\n\\ttrainy, testy = y[:n_train], y[n_train:]\\n\\treturn trainX, trainy, testX, testy\\n\\n# fit a model and plot learning curve\\ndef fit_model(trainX, trainy, testX, testy, n_batch):\\n\\t\\n  # define model\\n\\tmodel = Sequential()\\n\\tmodel.add(Dense(50, input_dim=2, activation=\\'relu\\', kernel_initializer=\\'he_uniform\\'))\\n\\tmodel.add(Dense(3, activation=\\'softmax\\'))\\n\\t\\n  # lr의 값을  0.1, 0.01, 0.001 중에서 선택하여 이곳에 지정\\n\\topt = SGD(lr=0.01, momentum=0.9) \\n\\tmodel.compile(loss=\\'categorical_crossentropy\\', optimizer=opt, metrics=[\\'accuracy\\'])\\n\\t# fit model\\n\\thistory = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=150, verbose=2, batch_size=n_batch)\\n\\tprint(\\'accuracy = \\', format(history.history[\\'accuracy\\'][149],\".3f\"), \\' \\', \\'va...\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'to_categorical' from 'keras.utils' (/usr/local/lib/python3.7/dist-packages/keras/utils/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}