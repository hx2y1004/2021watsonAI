{"cells": [{"metadata": {"colab": {}, "colab_type": "code", "id": "NCf2oMCBI4k9"}, "cell_type": "code", "source": "! pip install tensorflow==1.15", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n  from cryptography.utils import int_from_bytes\n/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n  from cryptography.utils import int_from_bytes\nRequirement already satisfied: tensorflow==1.15 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (1.15.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.15) (3.1.0)\nRequirement already satisfied: wrapt>=1.11.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.15) (1.12.1)\nRequirement already satisfied: astor>=0.6.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.15) (0.8.0)\nRequirement already satisfied: protobuf>=3.6.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.15) (3.12.3)\nRequirement already satisfied: numpy<2.0,>=1.16.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.15) (1.18.5)\nRequirement already satisfied: tensorflow-estimator==1.15.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.15) (1.15.1)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.15) (1.1.0)\nRequirement already satisfied: wheel>=0.26 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.15) (0.34.2)\nRequirement already satisfied: keras-applications>=1.0.8 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.15) (1.0.8)\nRequirement already satisfied: google-pasta>=0.1.6 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.15) (0.2.0)\nRequirement already satisfied: grpcio>=1.8.6 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.15) (1.27.2)\nRequirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.15) (1.15.0)\nRequirement already satisfied: absl-py>=0.7.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.15) (0.9.0)\nRequirement already satisfied: gast==0.2.2 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.15) (0.2.2)\nRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.15) (1.1.0)\nRequirement already satisfied: six>=1.10.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow==1.15) (1.15.0)\nRequirement already satisfied: setuptools in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow==1.15) (47.3.1.post20200622)\nRequirement already satisfied: h5py in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.1.1)\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "from __future__ import print_function\n#%tensorflow_version 1.x\n\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.examples.tutorials.mnist import input_data\n\nimport math\nimport os\nimport errno\nimport shutil", "execution_count": 2, "outputs": []}, {"metadata": {"colab": {}, "colab_type": "code", "id": "mZ-1elJrI4lg"}, "cell_type": "code", "source": "PLOT_DIR = './out/plots'", "execution_count": 3, "outputs": []}, {"metadata": {"colab": {}, "colab_type": "code", "id": "b9FWvSWZI4ln"}, "cell_type": "code", "source": "def get_grid_dim(x):\n    \"\"\"\n    Transforms x into product of two integers\n    :param x: int\n    :return: two ints\n    \"\"\"\n    factors = prime_powers(x)\n    if len(factors) % 2 == 0:\n        i = int(len(factors) / 2)\n        return factors[i], factors[i - 1]\n\n    i = len(factors) // 2\n    return factors[i], factors[i]\n\n\ndef prime_powers(n):\n    \"\"\"\n    Compute the factors of a positive integer\n    Algorithm from https://rosettacode.org/wiki/Factors_of_an_integer#Python\n    :param n: int\n    :return: set\n    \"\"\"\n    factors = set()\n    for x in range(1, int(math.sqrt(n)) + 1):\n        if n % x == 0:\n            factors.add(int(x))\n            factors.add(int(n // x))\n    return sorted(factors)\n\n\ndef empty_dir(path):\n    \"\"\"\n    Delete all files and folders in a directory\n    :param path: string, path to directory\n    :return: nothing\n    \"\"\"\n    for the_file in os.listdir(path):\n        file_path = os.path.join(path, the_file)\n        try:\n            if os.path.isfile(file_path):\n                os.unlink(file_path)\n            elif os.path.isdir(file_path):\n                shutil.rmtree(file_path)\n        except Exception as e:\n            print ('Warning: {}'.format(e))\n\n\ndef create_dir(path):\n    \"\"\"\n    Creates a directory\n    :param path: string\n    :return: nothing\n    \"\"\"\n    try:\n        os.makedirs(path)\n    except OSError as exc:\n        if exc.errno != errno.EEXIST:\n            raise\n\n\ndef prepare_dir(path, empty=False):\n    \"\"\"\n    Creates a directory if it soes not exist\n    :param path: string, path to desired directory\n    :param empty: boolean, delete all directory content if it exists\n    :return: nothing\n    \"\"\"\n    if not os.path.exists(path):\n        create_dir(path)\n\n    if empty:\n        empty_dir(path)", "execution_count": 4, "outputs": []}, {"metadata": {"colab": {}, "colab_type": "code", "id": "ZzN_52EVI4lq"}, "cell_type": "code", "source": "def plot_conv_weights(weights, name, channels_all=True):\n    \"\"\"\n    Plots convolutional filters\n    :param weights: numpy array of rank 4\n    :param name: string, name of convolutional layer\n    :param channels_all: boolean, optional\n    :return: nothing, plots are saved on the disk\n    \"\"\"\n    # make path to output folder\n    plot_dir = os.path.join(PLOT_DIR, 'conv_weights')\n    plot_dir = os.path.join(plot_dir, name)\n\n    # create directory if does not exist, otherwise empty it\n    # utils.prepare_dir(plot_dir, empty=True)\n    prepare_dir(plot_dir, empty=True)\n\n    w_min = np.min(weights)\n    w_max = np.max(weights)\n\n    channels = [0]\n    # make a list of channels if all are plotted\n    if channels_all:\n        channels = range(weights.shape[2])\n\n    # get number of convolutional filters\n    num_filters = weights.shape[3]\n\n    # get number of grid rows and columns\n    grid_r, grid_c = get_grid_dim(num_filters)\n\n    # create figure and axes\n    fig, axes = plt.subplots(min([grid_r, grid_c]),\n                             max([grid_r, grid_c]))\n\n    # iterate channels\n    for channel in channels:\n        # iterate filters inside every channel\n        for l, ax in enumerate(axes.flat):\n            # get a single filter\n            img = weights[:, :, channel, l]\n            # put it on the grid\n            ax.imshow(img, vmin=w_min, vmax=w_max, interpolation='nearest', cmap='seismic')\n            # remove any labels from the axes\n            ax.set_xticks([])\n            ax.set_yticks([])\n        # save figure\n        plt.savefig(os.path.join(plot_dir, '{}-{}.png'.format(name, channel)), bbox_inches='tight')\n\n\ndef plot_conv_output(conv_img, name):\n    \"\"\"\n    Makes plots of results of performing convolution\n    :param conv_img: numpy array of rank 4\n    :param name: string, name of convolutional layer\n    :return: nothing, plots are saved on the disk\n    \"\"\"\n    # make path to output folder\n    plot_dir = os.path.join(PLOT_DIR, 'conv_output')\n    plot_dir = os.path.join(plot_dir, name)\n\n    # create directory if does not exist, otherwise empty it\n    prepare_dir(plot_dir, empty=True)\n\n    w_min = np.min(conv_img)\n    w_max = np.max(conv_img)\n\n    # get number of convolutional filters\n    num_filters = conv_img.shape[3]\n\n    # get number of grid rows and columns\n    grid_r, grid_c = get_grid_dim(num_filters)\n\n    # create figure and axes\n    fig, axes = plt.subplots(min([grid_r, grid_c]),\n                             max([grid_r, grid_c]))\n\n    # iterate filters\n    for l, ax in enumerate(axes.flat):\n        # get a single image\n        img = conv_img[0, :, :,  l]\n        # put it on the grid\n        ax.imshow(img, vmin=w_min, vmax=w_max, interpolation='bicubic', cmap='Greys')\n        # remove any labels from the axes\n        ax.set_xticks([])\n        ax.set_yticks([])\n    # save figure\n    plt.savefig(os.path.join(plot_dir, '{}.png'.format(name)), bbox_inches='tight')", "execution_count": 5, "outputs": []}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 748}, "colab_type": "code", "id": "31V14lEAI4lw", "outputId": "63be20b8-32de-4af2-8b86-ebecf321a046"}, "cell_type": "code", "source": "mnist = input_data.read_data_sets(\"./data/\", one_hot=True)\n\n# Parameters\nlearning_rate = 0.001\ntraining_iters = 10000\nbatch_size = 128\ndisplay_step = 10\n\n# Network Parameters\nn_input = 784  # MNIST data input (img shape: 28*28)\nn_classes = 10  # MNIST total classes (0-9 digits)\ndropout = 0.75  # Dropout, probability to keep units\n\n# tf Graph input\nx = tf.placeholder(tf.float32, [None, n_input])\ny = tf.placeholder(tf.float32, [None, n_classes])\nkeep_prob = tf.placeholder(tf.float32)  # dropout (keep probability)\n\n\ndef conv2d(x_, filter_size, filter_num, stride=1):\n    \"\"\"\n    Wrapper of a convolutional layer\n    :param x_: tensor, input to convolutional layer\n    :param filter_size: int, size of a convolutional kernel\n    :param filter_num: int, number of convolutional kernels\n    :param stride: int, optional, stride\n    :return: tensor\n    \"\"\"\n    # get number of channels in input\n    channels = x_.get_shape()[3].value\n\n    # create weights tensor\n    weights = tf.Variable(tf.random_normal([filter_size, filter_size, channels, filter_num]))\n\n    # add weights tensor to collection\n    tf.add_to_collection('conv_weights', weights)\n\n    # create bias tensor\n    bias = tf.Variable(tf.random_normal([filter_num]))\n\n    # apply weights and biases\n    preactivations = tf.nn.conv2d(x_, weights, strides=[1, stride, stride, 1], padding='SAME')\n    preactivations = tf.nn.bias_add(preactivations, bias)\n\n    # apply activation function, this is layer output\n    activations = tf.nn.relu(preactivations)\n\n    # add output to collection\n    tf.add_to_collection('conv_output', activations)\n\n    return activations\n\n\ndef fc(x_, nodes, keep_prob_=1, act=tf.nn.relu):\n    \"\"\"\n    Wrapper for fully-connected layer\n    :param x_: tensor, input to fully-connected alyer\n    :param nodes: int, number of nodes in layer\n    :param keep_prob_: float, optional, keep probability for dropout operation\n    :param act: tf.nn method, optional, activation function\n    :return: tensor\n    \"\"\"\n    shape = x_.get_shape()\n\n    # if rank of input tensor is greater than 2\n    # we need to reshape it\n    if shape.ndims > 2:\n        n = 1\n        for s in shape[1:]:\n            n *= s.value\n        x_ = tf.reshape(x_, tf.stack([-1, n]))\n        x_.set_shape([None, n])\n\n    # get number of column in input tensor\n    n = x_.get_shape()[1].value\n\n    # create weights\n    weights = tf.Variable(tf.random_normal([n, nodes]))\n\n    # create biases\n    bias = tf.Variable(tf.random_normal([nodes]))\n\n    # apply weights and bias\n    preactivate = tf.add(tf.matmul(x_, weights), bias)\n    out = preactivate\n\n    # apply activation function if not None\n    if act is not None:\n        out = act(preactivate)\n\n    # apply dropout\n    out = tf.nn.dropout(out, keep_prob_)\n\n    return out\n\n\ndef maxpool(x_, size, stride):\n    \"\"\"\n    Wrapper for max-pooling layer\n    :param x_: tensor, input to max-pooling layer\n    :param size: int\n    :param stride: int\n    :return: tensor\n    \"\"\"\n    return tf.nn.max_pool(x_,\n                          ksize=[1, size, size, 1],\n                          strides=[1, stride, stride, 1],\n                          padding='SAME')\n\n# Reshape inputs\nx_reshaped = tf.reshape(x, shape=[-1, 28, 28, 1])\n\n# First convolutional layer\npredictions = conv2d(x_reshaped, filter_size=5, filter_num=32)\n\n# First max-pooling layer\npredictions = maxpool(predictions, 2, 2)\n\n# Second convolutional layer\npredictions = conv2d(predictions, filter_size=5, filter_num=64)\n\n# Second max-pooling layer\npredictions = maxpool(predictions, 2, 2)\n\n# First fully-connected layer\npredictions = fc(predictions, 1024, keep_prob)\n\n# Output layer, no activation function\n# This layer returns logits\npredictions = fc(predictions, n_classes, keep_prob, act=None)\n\n# Define loss operation\n#cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(predictions, y))\nval = tf.nn.softmax_cross_entropy_with_logits_v2(labels = y, logits = predictions) \ncost = tf.reduce_mean(val)\n\n\n# Define optimizer\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n\n# Define accuracy operation\ncorrect_predictions = tf.equal(tf.argmax(predictions, 1), tf.argmax(y, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n\n# Initializing the variables\ninit = tf.initialize_all_variables()", "execution_count": 6, "outputs": [{"output_type": "stream", "text": "WARNING:tensorflow:From <ipython-input-6-c6f22fff9fa7>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use alternatives such as official/mnist/dataset.py from tensorflow/models.\nWARNING:tensorflow:From /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease write your own downloading logic.\nWARNING:tensorflow:From /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use tf.data to implement this functionality.\nExtracting ./data/train-images-idx3-ubyte.gz\nWARNING:tensorflow:From /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use tf.data to implement this functionality.\nExtracting ./data/train-labels-idx1-ubyte.gz\nWARNING:tensorflow:From /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use tf.one_hot on tensors.\nExtracting ./data/t10k-images-idx3-ubyte.gz\nExtracting ./data/t10k-labels-idx1-ubyte.gz\nWARNING:tensorflow:From /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use alternatives such as official/mnist/dataset.py from tensorflow/models.\nWARNING:tensorflow:From <ipython-input-6-c6f22fff9fa7>:92: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\nWARNING:tensorflow:From /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/tensorflow_core/python/util/tf_should_use.py:198: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\nInstructions for updating:\nUse `tf.global_variables_initializer` instead.\n", "name": "stdout"}]}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 234}, "colab_type": "code", "id": "U5-X2WAVI4lz", "outputId": "3dd74379-d51f-4b8f-82fd-d559a05cf28b"}, "cell_type": "code", "source": "with tf.Session() as sess:\n    sess.run(init)\n    step = 1\n    # Keep training until reach max iterations\n    while step * batch_size < training_iters:\n        batch_x, batch_y = mnist.train.next_batch(batch_size)\n        # Run optimization op (backprop)\n        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y,\n                                   keep_prob: dropout})\n        if step % display_step == 0:\n            # Calculate batch loss and accuracy\n            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n                                                          y: batch_y,\n                                                          keep_prob: 1.})\n            print(\"\\rIter \" + str(step*batch_size) + \", Minibatch Loss= \" +\n              \"{:.6f}\".format(loss) + \", Training Accuracy= \" +\n              \"{:.5f}\".format(acc), end='')\n        step += 1\n    print(\"\\rOptimization Finished!\")\n    # Calculate accuracy for 256 mnist test images\n    print(\"Testing Accuracy:\",\n    sess.run(accuracy, feed_dict={x: mnist.test.images[:256],\n                                y: mnist.test.labels[:256],\n                                keep_prob: 1.}))\n    # no need for feed dictionary here\n    conv_weights = sess.run([tf.get_collection('conv_weights')])\n    conv_out = sess.run([tf.get_collection('conv_output')], feed_dict={x: mnist.test.images[:1]})\n    print(\"conv_weights & conv_out done!\")    ", "execution_count": 7, "outputs": [{"output_type": "stream", "text": "Optimization Finished!oss= 2824.694336, Training Accuracy= 0.843752\nTesting Accuracy: 0.8828125\nconv_weights & conv_out done!\n", "name": "stdout"}]}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 515}, "colab_type": "code", "id": "lim6jPpHI4l0", "outputId": "e9053ae4-b56e-47df-b5b5-1a9d8f5868e0"}, "cell_type": "code", "source": "  # get weights of all convolutional layers\n  # no need for feed dictionary here \n  for i, c in enumerate(conv_weights[0]):\n        plot_conv_weights(c, 'conv{}'.format(i))", "execution_count": null, "outputs": []}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 515}, "colab_type": "code", "id": "PPBut-HsS6KU", "outputId": "5e2ab874-5242-4dd3-94f6-ccec4c1b6d3d"}, "cell_type": "code", "source": " # get output of all convolutional layers\n # here we need to provide an input imag   \n   for i, c in enumerate(conv_out[0]): \n        plot_conv_output(c, 'conv{}'.format(i))\n#        ", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#", "execution_count": null, "outputs": []}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 1000}, "colab_type": "code", "id": "239iF48xe7xw", "outputId": "9a2ad7b6-e5bb-4b4d-b190-b60c4a4499e6"}, "cell_type": "code", "source": "#!ls -lR", "execution_count": null, "outputs": []}, {"metadata": {"colab": {}, "colab_type": "code", "id": "hlnB98l0I4l3"}, "cell_type": "code", "source": "  # print(conv_weights[0])", "execution_count": null, "outputs": []}, {"metadata": {"colab": {}, "colab_type": "code", "id": "52ZV9c5AI4l6"}, "cell_type": "code", "source": "#    print(conv_out[0])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"colab": {"collapsed_sections": [], "name": "MNIST CNN filter visualization copy 1.ipynb", "provenance": []}, "kernelspec": {"name": "python3", "display_name": "Python 3.7", "language": "python"}, "language_info": {"name": "python", "version": "3.7.10", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}